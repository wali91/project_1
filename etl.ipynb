{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "817cfd59-a54b-4394-9656-9d0e79711d0c",
   "metadata": {},
   "source": [
    "### **Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dc69a03-0055-4ae8-91d9-52ebb078f872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from config import oltp_conn_string, warehouse_conn_string, oltp_tables, warehouse_tables, dimension_columns, ddl_statements, ddl_marts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86f36d37-dd56-4c5f-8690-dd88bc6f510f",
   "metadata": {},
   "source": [
    "### **Function ETL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff56c09-846c-49c5-84c3-1491ffd98082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tables():\n",
    "    \"\"\"Create tables in the data warehouse if they do not exist.\"\"\"\n",
    "    engine = sa.create_engine(warehouse_conn_string)\n",
    "    with engine.connect() as conn:\n",
    "        for ddl in ddl_statements.values():\n",
    "            conn.execute(ddl)\n",
    "            \n",
    "def extract_data(table_name):\n",
    "    \"\"\"Extract data from a table in the OLTP database.\"\"\"\n",
    "    engine = sa.create_engine(oltp_conn_string)\n",
    "    query = f\"SELECT * FROM {oltp_tables[table_name]}\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f'Extract Data {oltp_tables[table_name]} Success')\n",
    "    return df\n",
    "\n",
    "def transform_data(df, target_table):\n",
    "    \"\"\"Transform the extracted data to match the schema of the target dimension table.\"\"\"\n",
    "    columns = dimension_columns.get(target_table)\n",
    "    if columns:\n",
    "        df = df[columns]\n",
    "    print(f'Transform Data {target_table} Success')\n",
    "    return df\n",
    "\n",
    "def transform_fact_orders():\n",
    "    \"\"\"Transform data for the fact_orders table.\"\"\"\n",
    "    dataframes = {table: extract_data(table) for table in oltp_tables.keys()}\n",
    "\n",
    "    df_orders = dataframes['orders']\n",
    "    df_orders = df_orders.merge(dataframes['users'], on='user_id')\n",
    "    df_orders = df_orders.merge(dataframes['payments'], on='payment_id')\n",
    "    df_orders = df_orders.merge(dataframes['shippers'], on='shipper_id')\n",
    "    df_orders = df_orders.merge(dataframes['ratings'], on='rating_id')\n",
    "    df_orders = df_orders.merge(dataframes['vouchers'], how='left', on='voucher_id')\n",
    "    df_orders.rename(columns={'user_id_x': 'user_id'}, inplace=True)\n",
    "    \n",
    "    fact_orders_columns = dimension_columns.get('fact_orders')\n",
    "    return df_orders[fact_orders_columns]\n",
    "\n",
    "# TRANSFORM fact order_items\n",
    "def transform_fact_order_items():\n",
    "    \"\"\"Transform data for the fact_orders table.\"\"\"\n",
    "    dataframes = {table: extract_data(table) for table in oltp_tables.keys()}\n",
    "\n",
    "    df_order_items = dataframes['order_items']\n",
    "    df_order_items = df_order_items.merge(dataframes['products'], on='product_id')\n",
    "    df_order_items = df_order_items.merge(dataframes['orders'], on='order_id')\n",
    "\n",
    "    fact_order_items_columns = dimension_columns.get('fact_order_items')\n",
    "    return df_order_items[fact_order_items_columns]\n",
    "\n",
    "\n",
    "def load_data(df, table_name):\n",
    "    \"\"\"Load the transformed data into the target table in the data warehouse.\"\"\"\n",
    "    engine = sa.create_engine(warehouse_conn_string)\n",
    "    with engine.connect() as conn:\n",
    "        # Cek kunci unique\n",
    "        unique_key = get_unique_key(table_name)  # Misalnya user_id untuk tabel dim_user\n",
    "        existing_data = pd.read_sql(f\"SELECT {unique_key} FROM {table_name}\", conn)\n",
    "        \n",
    "        # Deduplikasi data\n",
    "        df = deduplicate_data(df, existing_data, unique_key)\n",
    "        \n",
    "        # Masukkan data baru\n",
    "        df.to_sql(table_name, conn, index=False, if_exists='append', method='multi')\n",
    "        print(f'Load Data {table_name} Success')\n",
    "        \n",
    "def deduplicate_data(new_data, existing_data, unique_key):\n",
    "    \"\"\"Remove duplicates from new data based on existing data.\"\"\"\n",
    "    existing_keys = existing_data[unique_key].tolist()\n",
    "    unique_rows = new_data[~new_data[unique_key].isin(existing_keys)]\n",
    "    return unique_rows\n",
    "\n",
    "def get_unique_key(table_name):\n",
    "    \"\"\"Retrieve the unique key of the table.\"\"\"\n",
    "    if table_name == 'dim_user':\n",
    "        return 'user_id'\n",
    "    elif table_name == 'dim_payment':\n",
    "        return 'payment_id'\n",
    "    elif table_name == 'dim_shipper':\n",
    "        return 'shipper_id'\n",
    "    elif table_name == 'dim_rating':\n",
    "        return 'rating_id'\n",
    "    elif table_name == 'dim_voucher':\n",
    "        return 'voucher_id'\n",
    "    elif table_name == 'dim_products':\n",
    "        return 'product_id'\n",
    "    elif table_name == 'dim_product_category':\n",
    "        return 'product_category_id'\n",
    "    elif table_name == 'fact_orders':\n",
    "        return 'order_id'\n",
    "    elif table_name == 'fact_order_items':\n",
    "        return 'order_item_id'\n",
    "    # Tambahkan kondisi lain jika ada tabel lain\n",
    "    else:\n",
    "        raise ValueError(\"Table name not recognized.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8a0dab5-2f9d-472d-8350-ad46d2e7e60a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Function Data Mart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d93de0d-ea8e-422d-aa68-1c1132427704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_and_insert_dm_sales():\n",
    "    \"\"\"Create dm_sales table and insert data into it.\"\"\"\n",
    "    engine = sa.create_engine(warehouse_conn_string)\n",
    "    with engine.connect() as conn:\n",
    "        # Create dm_sales table\n",
    "        conn.execute(ddl_marts['dim_sales'])\n",
    "\n",
    "        # Insert data into dm_sales table\n",
    "        conn.execute(ddl_marts['insert_dm_sales'])\n",
    "    print(f'Data Mart Has Create Success')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f09cd1cd-e9ac-4a99-91f2-f3b9dcc28312",
   "metadata": {},
   "source": [
    "### **Function Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10330d98-0373-42aa-8307-caa46e6bf0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def etl_process():\n",
    "    \"\"\"Run the entire ETL process.\"\"\"\n",
    "    # Create tables\n",
    "    create_tables()\n",
    "\n",
    "    # Process dimension tables\n",
    "    for dim_table, target_table in warehouse_tables.items():\n",
    "        if dim_table != 'fact_orders':\n",
    "            source_table = dim_table\n",
    "            df = extract_data(source_table)\n",
    "            transformed_df = transform_data(df, dim_table)\n",
    "            load_data(transformed_df, target_table)\n",
    "        else:\n",
    "            # Process fact table\n",
    "            df_fact_orders = transform_fact_orders()\n",
    "            load_data(df_fact_orders, target_table)\n",
    "\n",
    "    # proses mart table\n",
    "    create_and_insert_dm_sales()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "615f468a-fb5f-476f-a7d0-5cca7d859a96",
   "metadata": {},
   "source": [
    "# **Run ETL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2738ed9d-6512-4f11-b7be-400976529462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Data tb_users Success\n",
      "Transform Data users Success\n",
      "Load Data dim_user Success\n",
      "Extract Data tb_payments Success\n",
      "Transform Data payments Success\n",
      "Load Data dim_payment Success\n",
      "Extract Data tb_shippers Success\n",
      "Transform Data shippers Success\n",
      "Load Data dim_shipper Success\n",
      "Extract Data tb_ratings Success\n",
      "Transform Data ratings Success\n",
      "Load Data dim_rating Success\n",
      "Extract Data tb_vouchers Success\n",
      "Transform Data vouchers Success\n",
      "Load Data dim_voucher Success\n",
      "Extract Data tb_orders Success\n",
      "Transform Data orders Success\n",
      "Load Data fact_orders Success\n",
      "Extract Data tb_product_category Success\n",
      "Transform Data product_category Success\n",
      "Load Data dim_product_category Success\n",
      "Extract Data tb_products Success\n",
      "Transform Data products Success\n",
      "Load Data dim_products Success\n",
      "Extract Data tb_order_items Success\n",
      "Transform Data order_items Success\n",
      "Load Data fact_order_items Success\n",
      "Data Mart Has Create Success\n"
     ]
    }
   ],
   "source": [
    "#script running all ETL\n",
    "etl_process()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63afee92-a119-4e39-9afd-5aec4b238e1b",
   "metadata": {},
   "source": [
    "### **Script Upload Google Sheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d66bc41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1MhPczHxgiQL8ZciSJQcMOKv9XAC7TXgpq2w8Dc9Uioo',\n",
       " 'updatedRange': 'sales!A1:O13',\n",
       " 'updatedRows': 13,\n",
       " 'updatedColumns': 15,\n",
       " 'updatedCells': 195}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_data_from_dwh(query):\n",
    "     # Membuat koneksi ke database\n",
    "    engine = sa.create_engine(warehouse_conn_string)\n",
    "    \n",
    "    # Membuat hasil query menjadi Datafrmae\n",
    "    df = pd.read_sql(query, engine)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_mart = fetch_data_from_dwh(\"\"\"SELECT * FROM dm_sales;\"\"\")\n",
    "\n",
    "with open('digitalskola_key.json','rb') as file:\n",
    "    key = json.load(file)\n",
    "    \n",
    "scope = ['https://www.googleapis.com/auth/drive','https://spreadsheets.google.com/feeds']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(key, scope)\n",
    "client = gspread.authorize(creds)\n",
    "sheet = client.open('datadg')\n",
    "\n",
    "export = sheet.worksheet(\"sales\")\n",
    "    \n",
    "export.update([df_mart.columns.values.tolist()] + df_mart.astype(str).values.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
